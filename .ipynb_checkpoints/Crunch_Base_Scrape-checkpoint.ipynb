{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.touch_actions import TouchActions\n",
    "from lxml import html\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "import tablib\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions\n",
    "def find_session_id(driver):\n",
    "\t# Find session_id\n",
    "\turl = driver.command_executor._url \n",
    "\tsession_id = driver.session_id  \n",
    "\n",
    "\tprint(\"url: \", url)\n",
    "\tprint(\"Session Id: \", session_id)\n",
    "    \n",
    "def organize_content(company, interested_field, field_content, description_info):\n",
    "    Content = {\"company\": company, \"content\": \"FOUND\"}\n",
    "    for interest in interested_field:\n",
    "        try:\n",
    "            idx = field_content.index(interest)\n",
    "            Content[str(interest)]=field_content[idx+1]\n",
    "        except:\n",
    "            Content[str(interest)]='N/A'\n",
    "    Content['description'] = description_info\n",
    "    return Content\n",
    "\n",
    "def found_company(driver, company):\n",
    "    # FIND CONTENT CARD\n",
    "    mat_card = driver.find_elements_by_xpath(\"/html[1]/body[1]/chrome[1]/div[1]/mat-sidenav-container[1]/mat-sidenav-content[1]/entity[1]/page-layout[1]/div[2]/div[1]/div[2]/div[1]/div[1]/entity-section[1]/section-layout[1]/mat-card[1]\")\n",
    "    content = mat_card[0].find_elements_by_class_name('section-layout-content')\n",
    "    # FIND FIELD CONTENT\n",
    "    field_content = content[0].text.split('\\n')\n",
    "    field_content = [cont.lower().strip() for cont in field_content]\n",
    "    # FIND DESCRIPTION\n",
    "    try: \n",
    "        description_info = content[0].find_elements_by_tag_name('description-card')[0].text\n",
    "    except:\n",
    "        description_info = \"N/A\"\n",
    "    # ORGANIZE INFORMATION\n",
    "    Content = organize_content(company, interested_field, field_content, description_info)\n",
    "    return Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url:  http://127.0.0.1:53614\n",
      "Session Id:  963ac38ede0b9ca1b84e125e04b11149\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome('./chromedriver')\n",
    "actions = ActionChains(driver)\n",
    "find_session_id(driver)\n",
    "# GO TO WEBSITE\n",
    "driver.get('https://www.crunchbase.com/')\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHECKING : Mindiply\n",
      "IS_COMPANY:  0\n",
      "Mindiply  FOUND\n",
      "______________________________________\n",
      "CHECKING : Mindler\n",
      "IS_COMPANY:  0\n",
      "Mindler  FOUND\n",
      "______________________________________\n",
      "CHECKING : MindMaze\n",
      "IS_COMPANY:  0\n",
      "MindMaze  FOUND\n",
      "______________________________________\n",
      "CHECKING : MindProber\n",
      "IS_COMPANY:  0\n",
      "MindProber  FOUND\n",
      "______________________________________\n",
      "CHECKING : Jonathan Levine\n",
      "IS_COMPANY:  -1\n",
      "Minds Matter  NOT FOUND\n",
      "CHECKING : Diane Chaleff\n",
      "IS_COMPANY:  -1\n",
      "Minds Matter  NOT FOUND\n",
      "CHECKING : Sarah Sommer\n",
      "IS_COMPANY:  -1\n",
      "Minds Matter  NOT FOUND\n",
      "CHECKING : Minds Matter\n",
      "IS_COMPANY:  0\n",
      "Minds Matter  FOUND\n",
      "______________________________________\n",
      "CHECKING : Mindsium\n",
      "IS_COMPANY:  0\n",
      "Mindsium  FOUND\n",
      "______________________________________\n",
      "CHECKING : MindStand Technologies\n",
      "IS_COMPANY:  0\n",
      "MindStand Technologies  FOUND\n",
      "______________________________________\n",
      "CHECKING : MindWeavers Ltd.\n",
      "IS_COMPANY:  0\n",
      "MindWeavers Ltd.  FOUND\n",
      "______________________________________\n",
      "CHECKING : Minerva Neuroscience\n",
      "IS_COMPANY:  0\n",
      "Minerva Neuroscience  FOUND\n",
      "______________________________________\n",
      "CHECKING : MINES and Associates\n",
      "IS_COMPANY:  0\n",
      "MINES and Associates  FOUND\n",
      "______________________________________\n",
      "CHECKING : MIPS AB\n",
      "IS_COMPANY:  0\n",
      "MIPS AB  FOUND\n",
      "______________________________________\n",
      "CHECKING : Miraisens\n",
      "IS_COMPANY:  0\n",
      "Miraisens  FOUND\n",
      "______________________________________\n",
      "CHECKING : MIVI Neuroscience\n",
      "IS_COMPANY:  0\n",
      "MIVI Neuroscience  FOUND\n",
      "______________________________________\n",
      "CHECKING : Minibar Delivery\n",
      "IS_COMPANY:  -1\n",
      "Mixers  NOT FOUND\n",
      "CHECKING : GreenDust\n",
      "IS_COMPANY:  -1\n",
      "Mixers  NOT FOUND\n",
      "CHECKING : Whirlpool\n",
      "IS_COMPANY:  -1\n",
      "Mixers  NOT FOUND\n",
      "CHECKING : Canvas Ventures\n",
      "IS_COMPANY:  -1\n",
      "Mixers  NOT FOUND\n",
      "CHECKING : Mixtroz\n",
      "IS_COMPANY:  -1\n",
      "Mixers  NOT FOUND\n",
      "______________________________________\n",
      "CHECKING : Miyabi Labs\n",
      "IS_COMPANY:  0\n",
      "Miyabi Labs  FOUND\n",
      "______________________________________\n",
      "CHECKING : Modern AlkaMe\n",
      "IS_COMPANY:  0\n",
      "Modern AlkaMe  FOUND\n",
      "______________________________________\n",
      "CHECKING : ModiusHealth\n",
      "IS_COMPANY:  0\n",
      "ModiusHealth  FOUND\n",
      "______________________________________\n",
      "CHECKING : MojoGuru\n",
      "IS_COMPANY:  0\n",
      "MojoGuru  FOUND\n",
      "______________________________________\n",
      "CHECKING : Analytical Proof\n",
      "IS_COMPANY:  -1\n",
      "Molecular Fingerprint  NOT FOUND\n",
      "CHECKING : Molecular Fingerprint\n",
      "IS_COMPANY:  0\n",
      "Molecular Fingerprint  FOUND\n",
      "______________________________________\n",
      "CHECKING : Mologic\n",
      "IS_COMPANY:  0\n",
      "Mologic  FOUND\n",
      "______________________________________\n",
      "______________________________________\n",
      "CHECKING : Monclarity\n",
      "IS_COMPANY:  0\n",
      "Monclarity  FOUND\n",
      "______________________________________\n",
      "CHECKING : Montage Healthcare Solutions\n",
      "IS_COMPANY:  0\n",
      "Montage Healthcare Solutions  FOUND\n",
      "______________________________________\n",
      "CHECKING : mooditor\n",
      "IS_COMPANY:  0\n",
      "mooditor  FOUND\n",
      "______________________________________\n",
      "CHECKING : MoodMaster\n",
      "IS_COMPANY:  0\n",
      "MoodMaster  FOUND\n",
      "______________________________________\n",
      "CHECKING : Moodpanda\n",
      "IS_COMPANY:  0\n",
      "Moodpanda  FOUND\n",
      "______________________________________\n",
      "CHECKING : Moodru\n",
      "IS_COMPANY:  0\n",
      "Moodru  FOUND\n",
      "______________________________________\n",
      "CHECKING : Babyscripts\n",
      "IS_COMPANY:  -1\n",
      "Mother  NOT FOUND\n",
      "CHECKING : Bill Gates\n",
      "IS_COMPANY:  -1\n",
      "Mother  NOT FOUND\n",
      "CHECKING : BillionToOne\n",
      "IS_COMPANY:  -1\n",
      "Mother  NOT FOUND\n",
      "CHECKING : Curology\n",
      "IS_COMPANY:  -1\n",
      "Mother  NOT FOUND\n",
      "CHECKING : busuu\n",
      "IS_COMPANY:  -1\n",
      "Mother  NOT FOUND\n",
      "______________________________________\n",
      "CHECKING : Motorika\n",
      "IS_COMPANY:  0\n",
      "Motorika  FOUND\n",
      "______________________________________\n",
      "CHECKING : MRI Interventions\n",
      "IS_COMPANY:  0\n",
      "MRI Interventions  FOUND\n",
      "______________________________________\n",
      "CHECKING : MTRE Advanced Technologies Ltd.\n",
      "IS_COMPANY:  0\n",
      "MTRE Advanced Technologies Ltd.  FOUND\n",
      "______________________________________\n",
      "CHECKING : Multi-Function Pet Bed\n",
      "IS_COMPANY:  0\n",
      "Multi-Function Pet Bed  FOUND\n",
      "______________________________________\n",
      "CHECKING : Musimap\n",
      "IS_COMPANY:  0\n",
      "Musimap  FOUND\n",
      "______________________________________\n",
      "CHECKING : Muttr.com\n",
      "IS_COMPANY:  0\n",
      "Muttr.com  FOUND\n",
      "______________________________________\n",
      "COULDN'T FIND  My Elephant Brain\n",
      "______________________________________\n",
      "CHECKING : My Possible Self\n",
      "IS_COMPANY:  0\n",
      "My Possible Self  FOUND\n",
      "______________________________________\n",
      "CHECKING : MyBrainTest\n",
      "IS_COMPANY:  0\n",
      "MyBrainTest  FOUND\n",
      "______________________________________\n",
      "CHECKING : MyCognition\n",
      "IS_COMPANY:  0\n",
      "MyCognition  FOUND\n",
      "______________________________________\n",
      "CHECKING : Myelin Communications\n",
      "IS_COMPANY:  0\n",
      "Myelin Communications  FOUND\n",
      "______________________________________\n",
      "COULDN'T FIND  Myfitbrain\n",
      "______________________________________\n",
      "CHECKING : MyHopeHub\n",
      "IS_COMPANY:  0\n",
      "MyHopeHub  FOUND\n",
      "______________________________________\n",
      "CHECKING : MyLoveJudge.com\n",
      "IS_COMPANY:  0\n",
      "MyLoveJudge.com  FOUND\n",
      "______________________________________\n",
      "CHECKING : Myndlift\n",
      "IS_COMPANY:  0\n",
      "Myndlift  FOUND\n",
      "______________________________________\n",
      "CHECKING : MyndYou\n",
      "IS_COMPANY:  0\n",
      "MyndYou  FOUND\n",
      "______________________________________\n",
      "CHECKING : MYOMO\n",
      "IS_COMPANY:  0\n",
      "MYOMO  FOUND\n",
      "______________________________________\n",
      "COULDN'T FIND  Naked Generations\n",
      "______________________________________\n",
      "COULDN'T FIND  Naluri Hidup\n",
      "______________________________________\n",
      "CHECKING : NAPGEAR\n",
      "IS_COMPANY:  0\n",
      "NAPGEAR  FOUND\n",
      "______________________________________\n",
      "CHECKING : Napseason\n",
      "IS_COMPANY:  0\n",
      "Napseason  FOUND\n",
      "______________________________________\n",
      "CHECKING : Nara Logics\n",
      "IS_COMPANY:  0\n",
      "Nara Logics  FOUND\n",
      "______________________________________\n",
      "CHECKING : Nathanson Dental\n",
      "IS_COMPANY:  0\n",
      "Nathanson Dental  FOUND\n",
      "______________________________________\n",
      "CHECKING : Ronald I. Dozoretz\n",
      "IS_COMPANY:  -1\n",
      "National Foundation for Mental Health  NOT FOUND\n",
      "CHECKING : National Foundation for Mental Health\n",
      "IS_COMPANY:  0\n",
      "National Foundation for Mental Health  FOUND\n",
      "______________________________________\n"
     ]
    }
   ],
   "source": [
    "with open('company_chris.txt') as f:\n",
    "    company_list = f.read().split('\\n')\n",
    "interested_field = ['operating status', 'funding status', 'last funding type', 'company type', 'website' , \n",
    "                    'last funding type', 'categories']\n",
    "Content_List = np.array([])\n",
    "wait_time = 1.5\n",
    "for idx_company, company_str in enumerate(company_list):\n",
    "    # SEARCH COMPANY\n",
    "    searchbar = driver.find_elements_by_xpath(\"//input[@id='mat-input-0']\")\n",
    "    searchbar[0].send_keys(company_str)\n",
    "    searchbar[0].clear()\n",
    "    searchbar[0].send_keys(Keys.RETURN)\n",
    "    time.sleep(wait_time)\n",
    "    \n",
    "    search_list = driver.find_elements_by_xpath(\"/html[1]/body[1]/chrome[1]/div[1]/mat-sidenav-container[1]/mat-sidenav-content[1]/search[1]/page-layout[1]/div[1]/div[1]/form[1]/div[2]/results[1]/div[1]/div[1]/div[3]/sheet-grid[1]/div[1]/div[1]/grid-body[1]/div[1]/div[1]\")\n",
    "    found = False\n",
    "    try:\n",
    "        for company_ele in search_list[0].find_elements_by_tag_name(\"grid-row\"):\n",
    "            verify_company = company_ele.text.split('\\n')[1]\n",
    "            is_company = verify_company.lower().find(company_str.lower())\n",
    "            print(\"CHECKING :\", company_ele.text.split('\\n')[1])\n",
    "            print(\"IS_COMPANY: \", is_company)\n",
    "            if is_company >= 0:\n",
    "                print(company_str, \" FOUND\")\n",
    "                found = True\n",
    "                # CLICK FIRST LINK\n",
    "                hyperlink_str = \"//a[@title='\" + verify_company + \"']\"\n",
    "                driver.find_element_by_xpath(hyperlink_str).click()\n",
    "                time.sleep(wait_time)\n",
    "                Content = found_company(driver, verify_company)\n",
    "                break\n",
    "            else:\n",
    "                print(company_str, \" NOT FOUND\")  \n",
    "                continue\n",
    "            print(\"\")\n",
    "        if not found:\n",
    "            Content = {\"company\": company_str, \"content\": \"NOT FOUND\"}\n",
    "        Content_List = np.append(Content_List, Content)\n",
    "        print(\"______________________________________\")\n",
    "    except:\n",
    "        print(\"COULDN'T FIND \", company_str)\n",
    "        print(\"______________________________________\")\n",
    "    time.sleep(wait_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def writeObjectToFile(obj, filepath):\n",
    "    with open(filepath, 'w') as outfile:\n",
    "        json.dump(obj, outfile)\n",
    "        outfile.close()\n",
    "\n",
    "dct = {idx: Content_List[idx] for idx, name in enumerate(Content_List)}\n",
    "writeObjectToFile(dct, 'content_list_chris.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tab_data = tablib.Dataset()\n",
    "data_str = open('content_list_chris.json').read()\n",
    "data = json.loads(data_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    if data[str(i)]['content'] == \"FOUND\":\n",
    "        tab_data.append([ data[str(i)]['company'], data[str(i)]['content'], data[str(i)]['operating status'],\n",
    "                    data[str(i)]['description'], data[str(i)]['funding status'], data[str(i)]['website'],\n",
    "                    data[str(i)]['last funding type'], data[str(i)]['company type'], data[str(i)]['categories']])\n",
    "    else:\n",
    "        tab_data.append([ data[str(i)]['company'], data[str(i)]['content'],'N/A','N/A','N/A','N/A','N/A','N/A','N/A'])\n",
    "    tab_data.headers = ['Company', 'Content', 'Operating Status', 'Description', 'Funding Status', 'Website', \n",
    "                        'Last Funding Type', 'Company Type', 'Categories' ]\n",
    "    \n",
    "csv_data = tab_data.export('csv')\n",
    "f = open(\"company_chris.csv\", \"w\")\n",
    "f.write(csv_data)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
