{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.touch_actions import TouchActions\n",
    "from lxml import html\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "import tablib\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions\n",
    "def find_session_id(driver):\n",
    "\t# Find session_id\n",
    "\turl = driver.command_executor._url \n",
    "\tsession_id = driver.session_id  \n",
    "\n",
    "\tprint(\"url: \", url)\n",
    "\tprint(\"Session Id: \", session_id)\n",
    "    \n",
    "def organize_content(company, interested_field, field_content, description_info):\n",
    "    Content = {\"company\": company, \"content\": \"FOUND\"}\n",
    "    for interest in interested_field:\n",
    "        try:\n",
    "            idx = field_content.index(interest)\n",
    "            Content[str(interest)]=field_content[idx+1]\n",
    "        except:\n",
    "            Content[str(interest)]='N/A'\n",
    "    Content['description'] = description_info\n",
    "    return Content\n",
    "\n",
    "def found_company(driver, company):\n",
    "    # FIND CONTENT CARD\n",
    "    mat_card = driver.find_elements_by_xpath(\"/html[1]/body[1]/chrome[1]/div[1]/mat-sidenav-container[1]/mat-sidenav-content[1]/entity[1]/page-layout[1]/div[2]/div[1]/div[2]/div[1]/div[1]/entity-section[1]/section-layout[1]/mat-card[1]\")\n",
    "    content = mat_card[0].find_elements_by_class_name('section-layout-content')\n",
    "    # FIND FIELD CONTENT\n",
    "    field_content = content[0].text.split('\\n')\n",
    "    field_content = [cont.lower().strip() for cont in field_content]\n",
    "    # FIND DESCRIPTION\n",
    "    try: \n",
    "        description_info = content[0].find_elements_by_tag_name('description-card')[0].text\n",
    "    except:\n",
    "        description_info = \"N/A\"\n",
    "    # ORGANIZE INFORMATION\n",
    "    Content = organize_content(company, interested_field, field_content, description_info)\n",
    "    return Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url:  http://127.0.0.1:49613\n",
      "Session Id:  67a14b047c2ceee5dbfa9d7f4c0b7185\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome('./chromedriver')\n",
    "actions = ActionChains(driver)\n",
    "find_session_id(driver)\n",
    "# GO TO WEBSITE\n",
    "driver.get('https://www.crunchbase.com/')\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHECKING : Ipsyt\n",
      "IS_COMPANY:  0\n",
      "Ipsyt  FOUND\n",
      "______________________________________\n",
      "CHECKING : Iris Technologies\n",
      "IS_COMPANY:  0\n",
      "Iris Technologies  FOUND\n",
      "______________________________________\n",
      "CHECKING : IRONCloud Industries\n",
      "IS_COMPANY:  0\n",
      "IRONCloud Industries  FOUND\n",
      "______________________________________\n",
      "CHECKING : IsoFit\n",
      "IS_COMPANY:  0\n",
      "IsoFit  FOUND\n",
      "______________________________________\n",
      "CHECKING : IT Service ArchiTechs\n",
      "IS_COMPANY:  0\n",
      "IT Service ArchiTechs  FOUND\n",
      "______________________________________\n",
      "CHECKING : Italian Hospital Group SpA\n",
      "IS_COMPANY:  0\n",
      "Italian Hospital Group SpA  FOUND\n",
      "______________________________________\n",
      "CHECKING : iwinks\n",
      "IS_COMPANY:  0\n",
      "iWinks  FOUND\n",
      "______________________________________\n",
      "CHECKING : Ixor\n",
      "IS_COMPANY:  0\n",
      "Ixor  FOUND\n",
      "______________________________________\n",
      "CHECKING : JAK Genetic and EMF Protection Svs\n",
      "IS_COMPANY:  0\n",
      "JAK Genetic and EMF Protection Svs  FOUND\n",
      "______________________________________\n",
      "CHECKING : Jan Medical\n",
      "IS_COMPANY:  0\n",
      "Jan Medical  FOUND\n",
      "______________________________________\n"
     ]
    }
   ],
   "source": [
    "with open('company_chris.txt') as f:\n",
    "    company_list = f.read().split('\\n')\n",
    "interested_field = ['operating status', 'funding status', 'last funding type', 'company type', 'website' , \n",
    "                    'last funding type', 'categories']\n",
    "Content_List = np.array([])\n",
    "wait_time = 1.5\n",
    "for idx_company, company_str in enumerate(company_list):\n",
    "    # SEARCH COMPANY\n",
    "    searchbar = driver.find_elements_by_xpath(\"//input[@id='mat-input-0']\")\n",
    "    searchbar[0].send_keys(company_str)\n",
    "    searchbar[0].clear()\n",
    "    searchbar[0].send_keys(Keys.RETURN)\n",
    "    time.sleep(wait_time)\n",
    "    \n",
    "    search_list = driver.find_elements_by_xpath(\"/html[1]/body[1]/chrome[1]/div[1]/mat-sidenav-container[1]/mat-sidenav-content[1]/search[1]/page-layout[1]/div[1]/div[1]/form[1]/div[2]/results[1]/div[1]/div[1]/div[3]/sheet-grid[1]/div[1]/div[1]/grid-body[1]/div[1]/div[1]\")\n",
    "    found = False\n",
    "    try:\n",
    "        for company_ele in search_list[0].find_elements_by_tag_name(\"grid-row\"):\n",
    "            verify_company = company_ele.text.split('\\n')[1]\n",
    "            is_company = verify_company.lower().find(company_str.lower())\n",
    "            print(\"CHECKING :\", company_ele.text.split('\\n')[1])\n",
    "            print(\"IS_COMPANY: \", is_company)\n",
    "            if is_company >= 0:\n",
    "                print(company_str, \" FOUND\")\n",
    "                found = True\n",
    "                # CLICK FIRST LINK\n",
    "                hyperlink_str = \"//a[@title='\" + verify_company + \"']\"\n",
    "                driver.find_element_by_xpath(hyperlink_str).click()\n",
    "                time.sleep(wait_time)\n",
    "                Content = found_company(driver, verify_company)\n",
    "                break\n",
    "            else:\n",
    "                print(company_str, \" NOT FOUND\")  \n",
    "                continue\n",
    "            print(\"\")\n",
    "        if not found:\n",
    "            Content = {\"company\": company_str, \"content\": \"NOT FOUND\"}\n",
    "        Content_List = np.append(Content_List, Content)\n",
    "        print(\"______________________________________\")\n",
    "    except:\n",
    "        print(\"COULDN'T FIND \", company_str)\n",
    "        print(\"______________________________________\")\n",
    "    time.sleep(wait_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def writeObjectToFile(obj, filepath):\n",
    "    with open(filepath, 'w') as outfile:\n",
    "        json.dump(obj, outfile)\n",
    "        outfile.close()\n",
    "\n",
    "dct = {idx: Content_List[idx] for idx, name in enumerate(Content_List)}\n",
    "writeObjectToFile(dct, 'content_list_chris1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tab_data = tablib.Dataset()\n",
    "data_str = open('content_list_chris.json').read()\n",
    "data = json.loads(data_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    if data[str(i)]['content'] == \"FOUND\":\n",
    "        tab_data.append([ data[str(i)]['company'], data[str(i)]['content'], data[str(i)]['operating status'],\n",
    "                    data[str(i)]['description'], data[str(i)]['funding status'], data[str(i)]['website'],\n",
    "                    data[str(i)]['last funding type'], data[str(i)]['company type'], data[str(i)]['categories']])\n",
    "    else:\n",
    "        tab_data.append([ data[str(i)]['company'], data[str(i)]['content'],'N/A','N/A','N/A','N/A','N/A','N/A','N/A'])\n",
    "    tab_data.headers = ['Company', 'Content', 'Operating Status', 'Description', 'Funding Status', 'Website', \n",
    "                        'Last Funding Type', 'Company Type', 'Categories' ]\n",
    "    \n",
    "csv_data = tab_data.export('csv')\n",
    "f = open(\"company_chris.csv\", \"w\")\n",
    "f.write(csv_data)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
